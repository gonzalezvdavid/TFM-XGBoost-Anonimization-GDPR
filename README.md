# TFM: XGBoost con AnonimizaciÃ³n y Privacidad Diferencial para DetecciÃ³n de Fraude

## ğŸ‘¨â€ğŸ’¼ InformaciÃ³n del Autor
**Desarrollador**: David GonzÃ¡lez  
**Email**: dalexx07.28@gmail.com  
**Rol**: Data Engineer & XGBoost Specialist  
**EspecializaciÃ³n**: XGBoost, Gradient Boosting, OptimizaciÃ³n de Modelos, Privacidad Diferencial  
**Programa**: MÃ¡ster en AnÃ¡lisis de Datos Masivos e Inteligencia Empresarial - UNIE  
**Fecha**: Abril 2025

## ğŸ”— Proyecto Grupal
Este repositorio forma parte del **TFM grupal sobre AnonimizaciÃ³n de Datos y Cumplimiento GDPR en LLMs**.

**ğŸ‘¥ Colaboradores del TFM**:
- **Armando Ita**: Random Forest - [ğŸ”— Repositorio](https://github.com/iansilva2305/tfm_anonimizacion)
- **Alexis Mendoza**: RegresiÃ³n LogÃ­stica - [ğŸ”— Repositorio](https://github.com/alexismendozac/TFM_Anonimizacion_RegresionLogistica/tree/main/notebooks)
- **David GonzÃ¡lez**: XGBoost (este repositorio)

## ğŸ¯ Enfoque EspecÃ­fico: XGBoost

### Â¿Por quÃ© XGBoost?
XGBoost (eXtreme Gradient Boosting) fue seleccionado por su **rendimiento superior en competiciones de machine learning** y su capacidad para detectar patrones complejos en datos financieros. Sin embargo, planteamos la hipÃ³tesis de que su dependencia en gradientes especÃ­ficos podrÃ­a hacerlo mÃ¡s vulnerable a las transformaciones de anonimizaciÃ³n.

### HipÃ³tesis de Trabajo
**"XGBoost, aunque potente, puede experimentar degradaciÃ³n significativa tras la anonimizaciÃ³n debido a su sensibilidad a las relaciones especÃ­ficas entre variables"**

### Resultados Obtenidos ğŸ“Š
- **F1-Score Original**: 86.33%
- **F1-Score Anonimizado**: 66.43%
- **Impacto**: -19.90% (DegradaciÃ³n significativa)
- **Ranking**: ğŸ¥ˆ **2Âº lugar** entre los 3 modelos evaluados (post-anonimizaciÃ³n)

### Lecciones Aprendidas
- XGBoost requiere **ajustes especÃ­ficos** para trabajar con datos anonimizados
- La **privacidad diferencial** tiene mayor impacto en modelos de gradient boosting
- Es necesario **rebalancear hiperparÃ¡metros** tras aplicar k-anonimato

## ğŸ—ï¸ Arquitectura de la SoluciÃ³n

### Pipeline de Procesamiento
```
ğŸ“ Dataset PaySim1 
    â†“
ğŸ”’ SeudonimizaciÃ³n (SHA-256)
    â†“  
ğŸ“Š K-Anonimato (k=10)
    â†“
ğŸ¯ L-Diversidad (l=2)
    â†“
ğŸ›¡ï¸ Privacidad Diferencial (Îµ=2.0)
    â†“
âš¡ XGBoost Training
    â†“
ğŸ“ˆ EvaluaciÃ³n GDPR
```

### TÃ©cnicas de AnonimizaciÃ³n Implementadas

| TÃ©cnica | ParÃ¡metros | Aplicado a | Impacto en XGBoost |
|---------|------------|------------|-------------------|
| **SeudonimizaciÃ³n** | SHA-256 | nameOrig, nameDest | âœ… Sin impacto directo |
| **K-Anonimato** | k=10 | amount, step | âš ï¸ Afecta gradientes especÃ­ficos |
| **L-Diversidad** | l=2 | type | âš ï¸ Reduce patrones de boosting |
| **Privacidad Diferencial** | Îµ=2.0 | Proceso de entrenamiento | ğŸ”´ Mayor impacto que en Random Forest |

## ğŸ“ Estructura del Proyecto

```
TFM-XGBoost-Anonimization-GDPR/
â”œâ”€â”€ src/                                    # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ comparativa_modelos_XGBOOST.py     # Script principal de comparaciÃ³n
â”‚   â”œâ”€â”€ eda_anonimizacion_fraud_detection.py # EDA especÃ­fico para fraude
â”‚   â””â”€â”€ eda_anonimizacion_modular.py       # AnÃ¡lisis modular de anonimizaciÃ³n
â”œâ”€â”€ notebooks/                              # AnÃ¡lisis interactivos
â”‚   â”œâ”€â”€ notebook_analisis_privacidad-utilidad.ipynb    # Trade-off privacidad-utilidad
â”‚   â”œâ”€â”€ notebook_deteccion_fraude_basico.ipynb         # DetecciÃ³n bÃ¡sica de fraude
â”‚   â””â”€â”€ notebook_EDA_anonimizacion_LLMs.ipynb          # EDA con integraciÃ³n LLMs
â”œâ”€â”€ dataset/                               #Datos 
â”‚   â”œâ”€â”€ sample_paysim1.csv                 #Conjunto de datos 
â”œâ”€â”€ results/                              #Resultados y mÃ©tricas
â”‚   â”œâ”€â”€ xgboost_metrics.json              #MÃ©tricas detalladas del modelo
â”‚   â”œâ”€â”€ comparison_results.csv            #ComparaciÃ³n con otros modelos
â”‚   â””â”€â”€ privacy_impact_analysis.xlsx      #AnÃ¡lisis de impacto de privacidad
â”œâ”€â”€ config/                               #Configuraciones
â”‚   â”œâ”€â”€ xgboost_params.yaml            #HiperparÃ¡metros optimizados
â”‚   â””â”€â”€ anonymization_config.json      #ConfiguraciÃ³n de anonimizaciÃ³n
â”œâ”€â”€ requirements.txt                   #Dependencias especÃ­ficas
â”œâ”€â”€ .gitignore                           #Archivos a ignorar
â””â”€â”€ README.md                           #Este archivo
```

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos
- Python 3.10+
- XGBoost 1.7.0+
- Scikit-learn 1.3.0+

### InstalaciÃ³n

1. **Clonar el repositorio:**
```bash
git clone https://https://github.com/gonzalezvdavid/TFM-XGBoost-Anonimization-GDPR
cd TFM-XGBoost-Anonimization-GDPR
```

2. **Crear entorno virtual:**
```bash
python -m venv xgboost_env
source xgboost_env/bin/activate  # En Windows: xgboost_env\Scripts\activate
```

3. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

### EjecuciÃ³n RÃ¡pida

```bash
# Ejecutar comparativa completa de modelos XGBoost
python src/comparativa_modelos_XGBOOST.py

# AnÃ¡lisis exploratorio para detecciÃ³n de fraude
python src/eda_anonimizacion_fraud_detection.py

# AnÃ¡lisis modular de tÃ©cnicas de anonimizaciÃ³n
python src/eda_anonimizacion_modular.py
```

### Ejecutar Notebooks

```bash
jupyter notebook notebooks/
```

**Orden recomendado de ejecuciÃ³n:**
1. `notebook_EDA_anonimizacion_LLMs.ipynb` - AnÃ¡lisis exploratorio inicial
2. `notebook_deteccion_fraude_basico.ipynb` - Modelo baseline
3. `notebook_analisis_privacidad-utilidad.ipynb` - EvaluaciÃ³n final

## ğŸ“Š Resultados Principales

### ComparaciÃ³n Detallada: XGBoost

| MÃ©trica | Original | Anonimizado | Impacto | InterpretaciÃ³n |
|---------|----------|-------------|---------|----------------|
| **PrecisiÃ³n** | 99.97% | 99.92% | -0.05% | âœ… Excelente |
| **Sensibilidad** | 80.60% | 59.66% | -20.94% | ğŸ”´ DegradaciÃ³n significativa |
| **F1-Score** | 86.33% | 66.43% | -19.90% | ğŸ”´ Requiere optimizaciÃ³n |

### AnÃ¡lisis del Impacto

**âœ… Fortalezas Mantenidas:**
- **PrecisiÃ³n alta**: 99.92% - Evita falsos positivos
- **Estructura del modelo**: XGBoost sigue siendo interpretable
- **Velocidad de inferencia**: No se ve afectada

**âš ï¸ Ãreas de DegradaciÃ³n:**
- **Sensibilidad**: PÃ©rdida significativa en detecciÃ³n de fraudes reales
- **Patrones complejos**: Dificultad para capturar relaciones sutiles post-anonimizaciÃ³n
- **Gradientes**: Los Ã¡rboles secuenciales son mÃ¡s sensibles a transformaciones

### Recomendaciones EspecÃ­ficas para XGBoost

1. **Ajustar hiperparÃ¡metros** post-anonimizaciÃ³n:
   - Reducir `learning_rate` a 0.05
   - Aumentar `n_estimators` a 200
   - Usar `reg_alpha` y `reg_lambda` mÃ¡s altos

2. **TÃ©cnicas de anonimizaciÃ³n especÃ­ficas**:
   - Considerar rangos mÃ¡s amplios en k-anonimato
   - Explorar diferent values de Îµ en privacidad diferencial

3. **Ensamble con otros modelos**:
   - Combinar con Random Forest para mayor robustez

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Core ML Stack
```python
xgboost==1.7.4
scikit-learn==1.3.0
pandas==2.0.3
numpy==1.24.3
```

### Privacidad y AnonimizaciÃ³n
```python
opacus==1.4.0              # Privacidad diferencial
diffprivlib==0.6.0         # Biblioteca de IBM para DP
faker==19.6.2              # GeneraciÃ³n de datos sintÃ©ticos
```

### AnÃ¡lisis y VisualizaciÃ³n
```python
matplotlib==3.7.2
seaborn==0.12.2
plotly==5.15.0
jupyter==1.0.0
```

## ğŸ“ˆ Impacto y Contribuciones

### Contribuciones TÃ©cnicas
- **ğŸ“Š AnÃ¡lisis exhaustivo** del impacto de anonimizaciÃ³n en gradient boosting
- **âš™ï¸ OptimizaciÃ³n especÃ­fica** de hiperparÃ¡metros para datos anonimizados
- **ğŸ” IdentificaciÃ³n** de limitaciones de XGBoost en contextos GDPR
- **ğŸ“‹ Framework** replicable para evaluaciÃ³n de modelos de boosting

### Implicaciones para la Industria
- **Bancos**: Consideraciones especiales para modelos XGBoost con datos anonimizados
- **Reguladores**: Evidencia de que algunos algoritmos requieren mayor cuidado
- **Desarrolladores ML**: GuÃ­a prÃ¡ctica para optimizaciÃ³n post-anonimizaciÃ³n

## ğŸ”¬ MetodologÃ­a de InvestigaciÃ³n

### HipÃ³tesis Evaluadas
1. **H1**: XGBoost mantendrÃ¡ rendimiento superior tras anonimizaciÃ³n âŒ
2. **H2**: Privacidad diferencial afectarÃ¡ mÃ¡s a XGBoost que a Random Forest âœ…
3. **H3**: K-anonimato impactarÃ¡ gradientes de boosting âœ…

### Experimentos Realizados
- **Baseline**: XGBoost sin anonimizaciÃ³n
- **AnonimizaciÃ³n bÃ¡sica**: Solo seudonimizaciÃ³n
- **AnonimizaciÃ³n completa**: Pipeline completo (k-anonimato + l-diversidad + DP)
- **OptimizaciÃ³n**: Ajuste de hiperparÃ¡metros post-anonimizaciÃ³n

## ğŸ“ DocumentaciÃ³n Adicional

### Informes Detallados
- [ğŸ“Š AnÃ¡lisis de Impacto XGBoost](results/xgboost_impact_analysis.pdf)
- [âš™ï¸ GuÃ­a de OptimizaciÃ³n](docs/xgboost_optimization_guide.md)
- [ğŸ”’ Reporte de Cumplimiento GDPR](docs/gdpr_compliance_report.pdf)

### Notebooks de Apoyo
- [ğŸ§® CalibraciÃ³n de HiperparÃ¡metros](notebooks/hyperparameter_tuning.ipynb)
- [ğŸ“ˆ AnÃ¡lisis de Sensibilidad](notebooks/sensitivity_analysis.ipynb)
- [ğŸ¯ OptimizaciÃ³n Post-AnonimizaciÃ³n](notebooks/post_anonymization_optimization.ipynb)

## ğŸ“ Contexto AcadÃ©mico

**Trabajo Final de MÃ¡ster**: AnonimizaciÃ³n de Datos Personales y Cumplimiento del GDPR en Datos Generados por Modelos de Lenguaje de Gran Escala (LLMs)

**Tutor**: DesirÃ©e Delgado  
**Universidad**: UNIE  
**MÃ¡ster**: AnÃ¡lisis de Datos Masivos e Inteligencia Empresarial

## ğŸ¤ ColaboraciÃ³n y Contribuciones

### CÃ³mo Contribuir
1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-optimizacion`)
3. Commit tus cambios (`git commit -am 'AÃ±adir nueva optimizaciÃ³n XGBoost'`)
4. Push a la rama (`git push origin feature/nueva-optimizacion`)
5. Crea un Pull Request

### Issues y Mejoras
- ğŸ› Reportar bugs en la implementaciÃ³n
- ğŸ’¡ Sugerir nuevas tÃ©cnicas de optimizaciÃ³n
- ğŸ“š Mejorar documentaciÃ³n
- ğŸ§ª AÃ±adir nuevos experimentos

## ğŸ“ Contacto

**David GonzÃ¡lez**  
ğŸ“§ Email: dalexx07.28@gmail.com  
ğŸ’¼ LinkedIn: [David GonzÃ¡lez - Data Engineer](https://www.linkedin.com/in/davidgnzlez/)  
ğŸ™ GitHub: [@davidgonzalez](https://github.com/gonzalezvdavid)

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ™ Agradecimientos

- **DesirÃ©e Delgado**: SupervisiÃ³n acadÃ©mica y orientaciÃ³n metodolÃ³gica
- **Armando Ita**: ColaboraciÃ³n en Random Forest e intercambio de insights
- **Alexis Mendoza**: Trabajo en RegresiÃ³n LogÃ­stica y anÃ¡lisis comparativo
- **Universidad UNIE**: Marco acadÃ©mico y recursos de investigaciÃ³n
- **Comunidad XGBoost**: DocumentaciÃ³n y best practices

---

## ğŸ“Š EstadÃ­sticas del Proyecto

![GitHub last commit](https://img.shields.io/github/last-commit/davidgonzalez/TFM-XGBoost-Anonimization-GDPR)
![GitHub repo size](https://img.shields.io/github/repo-size/davidgonzalez/TFM-XGBoost-Anonimization-GDPR)
![Python](https://img.shields.io/badge/python-v3.10+-blue.svg)
![XGBoost](https://img.shields.io/badge/XGBoost-v1.7+-orange.svg)
![GDPR](https://img.shields.io/badge/GDPR-Compliant-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

---

*"Optimizando XGBoost para un mundo donde la privacidad y el rendimiento coexisten"*
